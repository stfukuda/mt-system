{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"MT-system documentation","text":""},{"location":"#description","title":"Description","text":"<p>MT-system is a scikit-learn based Python library for computing quality engineering MT system. It provides the following methods ( models ) with scikit-learn compatible API:</p>"},{"location":"#models","title":"Models","text":"<p>Pattern Recognition</p> <ul> <li>MT</li> <li>MTA</li> <li>SVP: Standardized-Variation-Pressure</li> <li>RT</li> </ul> <p>Regression</p> <ul> <li>T (1)</li> <li>T (2)</li> <li>Ta</li> <li>Tb</li> <li>MSR</li> </ul>"},{"location":"api/","title":"MTS","text":""},{"location":"api/#src.mts","title":"<code>mts</code>","text":"<p>The 'mts' module contains various methods of the MT system.</p>"},{"location":"api/#src.mts.MSR","title":"<code>MSR(*, delta=0.0001, esp=1e-16)</code>","text":"<p>               Bases: <code>RegressorMixin</code>, <code>BaseEstimator</code></p> <p>MSR: Multiple Single Regression.</p> <p>Parameters:</p> Name Type Description Default <code>delta</code> <code>float</code> <p>Threshold for stopping repeated computations.</p> <code>1e-4</code> <code>esp</code> <code>float</code> <p>A constant to avoid zero division. It is used in the calculation as <code>1 / (x + esp)</code>.</p> <code>1e-16</code> <p>Attributes:</p> Name Type Description <code>mean_X_</code> <code>ndarray of shape(n_features, )</code> <p>Mean values of each feature of the training data.</p> <code>mean_y_</code> <code>float</code> <p>Mean value of target values.</p> <code>coef_</code> <code>ndarray of shape (n_features, )</code> <p>Estimated coefficients for the MSR.</p> <code>n_features_in_</code> <code>int</code> <p>Number of features seen during fit.</p> <code>feature_names_in_</code> <code>ndarray of shape (n_features_in_, )</code> <p>Names of features seen during the fit. Defined only if X has feature names that are all strings.</p> References <p>\u524d\u7530\u8aa0. (2017). T \u6cd5 (1) \u306e\u8003\u3048\u65b9\u3092\u5229\u7528\u3057\u305f\u65b0\u3057\u3044\u56de\u5e30\u624b\u6cd5\u306e\u63d0\u6848. \u54c1\u8cea, 47(2), 185-194.</p> <p>Methods:</p> Name Description <code>fit</code> <p>Fit the model.</p> <code>predict</code> <p>Predict using the fitted model.</p> Source code in <code>src/mts/_msr.py</code> <pre><code>def __init__(self, *, delta: float = 1e-4, esp: float = 1e-16):\n    \"\"\"\n    Initialize the instance.\n\n    Parameters\n    ----------\n    delta : float, default=1e-4\n        Threshold for stopping repeated computations.\n\n    esp : float, default=1e-16\n        A constant to avoid zero division. It is used in the calculation as\n        `1 / (x + esp)`.\n\n    Attributes\n    ----------\n    mean_X_ : ndarray of shape(n_features, )\n        Mean values of each feature of the training data.\n\n    mean_y_ : float\n        Mean value of target values.\n\n    coef_ : ndarray of shape (n_features, )\n        Estimated coefficients for the MSR.\n\n    n_features_in_ : int\n        Number of features seen during fit.\n\n    feature_names_in_ : ndarray of shape (n_features_in_, )\n        Names of features seen during the fit. Defined only if X has feature\n        names that are all strings.\n\n    References\n    ----------\n    \u524d\u7530\u8aa0. (2017). T \u6cd5 (1) \u306e\u8003\u3048\u65b9\u3092\u5229\u7528\u3057\u305f\u65b0\u3057\u3044\u56de\u5e30\u624b\u6cd5\u306e\u63d0\u6848. \u54c1\u8cea, 47(2),\n    185-194.\n    \"\"\"\n    self.delta = delta\n    self.esp = esp\n</code></pre>"},{"location":"api/#src.mts.MSR.fit","title":"<code>fit(X, y)</code>","text":"<p>Fit the model.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray of shape (n_samples, n_features)</code> <p>Training data.</p> required <code>y</code> <code>ndarray of shape (n_samples, )</code> <p>Target values. Will be cast to X's dtype if necessary.</p> required <p>Returns:</p> Name Type Description <code>self</code> <code>object</code> <p>Fitted model.</p> Source code in <code>src/mts/_msr.py</code> <pre><code>def fit(self, X, y):\n    \"\"\"\n    Fit the model.\n\n    Parameters\n    ----------\n    X : ndarray of shape (n_samples, n_features)\n        Training data.\n\n    y : ndarray of shape (n_samples, )\n        Target values. Will be cast to X's dtype if necessary.\n\n    Returns\n    -------\n    self : object\n        Fitted model.\n    \"\"\"\n    self._validate_params()  # type: ignore\n\n    X, y = self._validate_data(  # type: ignore\n        X=X,\n        y=y,\n        reset=True,\n        y_numeric=True,\n        ensure_min_samples=2,\n        estimator=self,\n    )\n\n    n_samples, n_features = X.shape\n\n    if n_samples &lt;= 50:\n        n_splits = n_samples\n    else:\n        n_splits = int(2250 / n_samples) + 5\n\n    kf = KFold(n_splits=n_splits)\n\n    self.coef_ = np.zeros(n_features)\n    coef_kf = np.zeros((n_splits, n_features))\n\n    self.mean_X_ = np.mean(X, axis=0)\n    self.mean_y_ = np.mean(y)\n\n    std_X = X - self.mean_X_[None, :]\n    std_y = y - self.mean_y_\n\n    zz_before = None\n    skip_kf = []\n    while True:\n        y_ = np.dot(std_X, self.coef_)\n\n        z = std_y - y_\n\n        st, sb, n, b = self._compute_sn_ratio_and_sensitivity(std_X, z)\n\n        if st == 0 or np.all(sb == 0):\n            break\n\n        self.coef_ += b * n / np.sum(n)\n\n        z = np.empty(n_samples)\n        for kf_idx, (train_idx, test_idx) in enumerate(kf.split(std_X)):\n            train_X, train_y = std_X[train_idx], std_y[train_idx]\n            test_X, test_y = std_X[test_idx], std_y[test_idx]\n\n            if kf_idx in skip_kf:\n                y_kf = np.dot(test_X, coef_kf[kf_idx])\n                z[test_idx] = test_y - y_kf\n                continue\n\n            y_kf = np.dot(train_X, coef_kf[kf_idx])\n            z_kf = train_y - y_kf\n\n            st, sb, n, b = self._compute_sn_ratio_and_sensitivity(train_X, z_kf)\n\n            if st == 0 or np.all(sb == 0):\n                skip_kf.append(kf_idx)\n                y_kf = np.dot(test_X, coef_kf[kf_idx])\n                z[test_idx] = test_y - y_kf\n                continue\n\n            coef_kf[kf_idx] += b * n / np.sum(n)\n\n            y_kf = np.dot(test_X, coef_kf[kf_idx])\n            z[test_idx] = test_y - y_kf\n\n        zz_after = np.dot(z, z)\n\n        if zz_before is None:\n            zz_before = zz_after * 2\n\n        if (zz_before - zz_after) &lt;= (self.delta * zz_before):\n            break\n        else:\n            zz_before = zz_after\n\n    return self\n</code></pre>"},{"location":"api/#src.mts.MSR.predict","title":"<code>predict(X, y=None)</code>","text":"<p>Predict using the fitted model.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray of shape (n_samples, n_features)</code> <p>Samples.</p> required <code>y</code> <code>None</code> <p>Ignored.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>y_pred</code> <code>ndarray of shape (n_samples, )</code> <p>Predicted values.</p> Source code in <code>src/mts/_msr.py</code> <pre><code>def predict(self, X, y=None):\n    \"\"\"\n    Predict using the fitted model.\n\n    Parameters\n    ----------\n    X : ndarray of shape (n_samples, n_features)\n        Samples.\n\n    y : None\n        Ignored.\n\n    Returns\n    -------\n    y_pred : ndarray of shape (n_samples, )\n        Predicted values.\n    \"\"\"\n    check_is_fitted(self)\n\n    X = self._validate_data(X=X, reset=False)  # type: ignore\n\n    std_X = X - self.mean_X_[None, :]\n\n    return np.dot(std_X, self.coef_) + self.mean_y_\n</code></pre>"},{"location":"api/#src.mts.MT","title":"<code>MT(*, method='mt', ddof=1, esp=1e-16, kind='specify', a=0.05, threshold=4.0, return_sqrt=False)</code>","text":"<p>               Bases: <code>BaseEstimator</code></p> <p>MT, MTA and Standardized-Variation-Pressure methods.</p> <p>The MT, MTA and SVP methods are unsupervised learning methods used for pattern recognition in quality engineering. These methods learn the mean and standard deviation of each feature and the inverse correlation matrix of the training data, and compute MD values based on these values. The training data is called the unit space and usually contains only normal data. The MTA method learns an adjoint matrix instead of an inverse matrix to deal with multicolinearity. The SVP method does not require a correlation matrix.</p> <p>Parameters:</p> Name Type Description Default <code>method</code> <code>(mt, mta, svp)</code> <p>Computation method.</p> <code>\"mt\"</code> <code>ddof</code> <code>int</code> <p>It means the delta degrees of freedom. The divisor used in the is <code>N - ddof</code>, where <code>N</code> is the number of samples.</p> <code>1</code> <code>esp</code> <code>float</code> <p>A constant to avoid zero division. It is used in the calculation as <code>1 / (x + esp)</code>.</p> <code>1e-16</code> <code>kind</code> <code>(k, f, chi2, specify)</code> <p>The distribution used to determine normal and abnormal thresholds.</p> <code>\"k\"</code> <code>a</code> <code>float</code> <p>Right side significance level. Use to set the threshold when type is set to <code>f</code> or <code>chi2</code>.</p> <code>0.05</code> <code>threshold</code> <code>float</code> <p>Threshold to use when <code>kind</code> is set to <code>specify</code>.</p> <code>4.0</code> <code>return_sqrt</code> <code>bool</code> <p>Return the square root of the MD value or not.</p> <code>False</code> <p>Attributes:</p> Name Type Description <code>mean_</code> <code>ndarray of shape (n_features, )</code> <p>Means of each feature of the training data.</p> <code>scale_</code> <code>ndarray of shape (n_features, )</code> <p>Standard deviation values of each feature of the training data.</p> <code>covariance_</code> <code>ndarray of shape (n_features, n_features)</code> <p>Correlation matrix, variance-covariance matrix, or identity matrix of the training data; correlation matrix if \"method\" is \"mt\", variance-covariance matrix if \"method\" is \"mta\", or identity matrix if \"method\" is \"svp\".</p> <code>precision_</code> <code>ndarray of shape (n_features, n_features)</code> <p>The inverse matrix or adjoint matrix of covariance_; if method is svp, then identity matrix.</p> <code>dist_</code> <code>ndarray of shape(n_samples, )</code> <p>Mahalanobis distances of the training set (on which the fit is called) observations.</p> <code>n_features_in_</code> <code>int</code> <p>Number of features seen during fit.</p> <code>feature_names_in_</code> <code>ndarray of shape (n_features_in_, )</code> <p>Names of features seen during the fit. Defined only if X has feature names that are all strings.</p> <p>Methods:</p> Name Description <code>fit</code> <p>Fit the model.</p> <code>predict</code> <p>Predict the labels of X according to the fitted model.</p> <code>fit_predict</code> <p>Perform Fit to X and Return Labels for X.</p> <code>mahalanobis</code> <p>Compute the Mahalanobis distances (MD values).</p> <code>score</code> <p>Return the ROCAUC to the given test data and labels.</p> <code>score_samples</code> <p>Compute the Mahalanobis distances (MD values).</p> Source code in <code>src/mts/_mt.py</code> <pre><code>def __init__(\n    self,\n    *,\n    method: str = \"mt\",\n    ddof: int = 1,\n    esp: float = 1e-16,\n    kind: str = \"specify\",\n    a: float = 0.05,\n    threshold: float = 4.0,\n    return_sqrt: bool = False,\n):\n    \"\"\"\n    Initialize the instance.\n\n    Parameters\n    ----------\n    method : {\"mt\", \"mta\", \"svp\"}, default=\"mt\"\n        Computation method.\n\n    ddof : int, default=1\n        It means the delta degrees of freedom. The divisor used in the is\n        `N - ddof`, where `N` is the number of samples.\n\n    esp : float, default=1e-16\n        A constant to avoid zero division. It is used in the calculation as\n        `1 / (x + esp)`.\n\n    kind : {\"k\", \"f\", \"chi2\", \"specify\"}, default=\"specify\"\n        The distribution used to determine normal and abnormal thresholds.\n\n    a : float, default=0.05\n        Right side significance level. Use to set the threshold when type is\n        set to `f` or `chi2`.\n\n    threshold : float, default=4.0\n        Threshold to use when `kind` is set to `specify`.\n\n    return_sqrt : bool, default=False\n        Return the square root of the MD value or not.\n\n    Attributes\n    ----------\n    mean_ : ndarray of shape (n_features, )\n        Means of each feature of the training data.\n\n    scale_ : ndarray of shape (n_features, )\n        Standard deviation values of each feature of the training data.\n\n    covariance_ : ndarray of shape (n_features, n_features)\n        Correlation matrix, variance-covariance matrix, or identity matrix\n        of the training data; correlation matrix if \"method\" is \"mt\",\n        variance-covariance matrix if \"method\" is \"mta\", or identity matrix\n        if \"method\" is \"svp\".\n\n    precision_ : ndarray of shape (n_features, n_features)\n        The inverse matrix or adjoint matrix of covariance_; if method is\n        svp, then identity matrix.\n\n    dist_ : ndarray of shape(n_samples, )\n        Mahalanobis distances of the training set (on which the fit is\n        called) observations.\n\n    n_features_in_ : int\n        Number of features seen during fit.\n\n    feature_names_in_ : ndarray of shape (n_features_in_, )\n        Names of features seen during the fit. Defined only if X has feature\n        names that are all strings.\n    \"\"\"\n    self.method = method\n    self.ddof = ddof\n    self.esp = esp\n    self.kind = kind\n    self.a = a\n    self.threshold = threshold\n    self.return_sqrt = return_sqrt\n</code></pre>"},{"location":"api/#src.mts.MT.fit","title":"<code>fit(X, y=None)</code>","text":"<p>Fit the model.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray of shape (n_samples, n_features)</code> <p>Training data.</p> required <code>y</code> <code>None</code> <p>Ignore</p> <code>None</code> <p>Returns:</p> Name Type Description <code>self</code> <code>object</code> <p>Fitted model.</p> Source code in <code>src/mts/_mt.py</code> <pre><code>def fit(self, X, y=None):\n    \"\"\"\n    Fit the model.\n\n    Parameters\n    ----------\n    X : ndarray of shape (n_samples, n_features)\n        Training data.\n\n    y : None\n        Ignore\n\n    Returns\n    -------\n    self : object\n        Fitted model.\n    \"\"\"\n    self._validate_params()  # type: ignore\n\n    X = self._validate_data(  # type: ignore\n        X=X,\n        reset=True,\n        ensure_min_samples=2,\n        ensure_min_features=2,\n        estimator=self,\n    )\n\n    n, k = X.shape  # type: ignore\n\n    self.mean_ = np.mean(X, axis=0)\n    self.scale_ = np.std(X, ddof=self.ddof, axis=0)\n\n    if self.method == \"mt\":\n        std_X = (X - self.mean_[None, :]) / (self.scale_[None, :] + self.esp)\n        self.covariance_ = np.corrcoef(std_X, rowvar=False)\n    elif self.method == \"mta\":\n        std_X = X - self.mean_[None, :]\n        self.covariance_ = np.cov(std_X, rowvar=False)\n    else:\n        self.covariance_ = np.eye(k)\n\n    self.precision_ = self._get_precision(self.covariance_)\n\n    self.dist_ = self._mahalanobis(X, self.mean_, self.scale_, self.precision_)\n\n    if self.kind == \"k\":\n        self.threshold_ = 4 * k\n    elif self.kind == \"f\":\n        self.threshold_ = (\n            (k * (n - 1) * (n + 1)) / (n * (n - k)) * f.isf(self.a, k, n - k)\n        )\n    elif self.kind == \"chi2\":\n        self.threshold_ = chi2.isf(self.a, k)\n    else:\n        self.threshold_ = self.threshold\n\n    return self\n</code></pre>"},{"location":"api/#src.mts.MT.predict","title":"<code>predict(X, y=None)</code>","text":"<p>Predict the labels of X according to the fitted model.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray of shape (n_samples, n_features)</code> <p>Samples.</p> required <code>y</code> <code>None</code> <p>Ignored.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>labels</code> <code>ndarray of shape (n_samples, )</code> <p>Returns 1 for anomalies/outliers and 0 for inliers.</p> Source code in <code>src/mts/_mt.py</code> <pre><code>def predict(self, X, y=None):\n    \"\"\"\n    Predict the labels of X according to the fitted model.\n\n    Parameters\n    ----------\n    X : ndarray of shape (n_samples, n_features)\n        Samples.\n\n    y : None\n        Ignored.\n\n    Returns\n    -------\n    labels : ndarray of shape (n_samples, )\n        Returns 1 for anomalies/outliers and 0 for inliers.\n    \"\"\"\n    check_is_fitted(self)\n\n    return np.where(self.mahalanobis(X=X) &gt;= self.threshold_, 1, 0)\n</code></pre>"},{"location":"api/#src.mts.MT.fit_predict","title":"<code>fit_predict(X, y=None)</code>","text":"<p>Perform Fit to X and Return Labels for X.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray of shape (n_samples, n_features)</code> <p>Input data.</p> required <code>y</code> <code>None</code> <p>Ignored.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>labels</code> <code>ndarray of shape (n_samples, )</code> <p>Returns 1 for anomalies/outliers and 0 for inliers.</p> Source code in <code>src/mts/_mt.py</code> <pre><code>def fit_predict(self, X, y=None):\n    \"\"\"\n    Perform Fit to X and Return Labels for X.\n\n    Parameters\n    ----------\n    X : ndarray of shape (n_samples, n_features)\n        Input data.\n\n    y : None\n        Ignored.\n\n    Returns\n    -------\n    labels : ndarray of shape (n_samples, )\n        Returns 1 for anomalies/outliers and 0 for inliers.\n    \"\"\"\n    return self.fit(X).predict(X)\n</code></pre>"},{"location":"api/#src.mts.MT.mahalanobis","title":"<code>mahalanobis(X)</code>","text":"<p>Compute the Mahalanobis distances (MD values).</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray of shape (n_samples, n_features)</code> <p>Samples.</p> required <p>Returns:</p> Name Type Description <code>MD</code> <code>ndarray of shape (n_samples, )</code> <p>Mahalanobis distances (MD values).</p> Source code in <code>src/mts/_mt.py</code> <pre><code>def mahalanobis(self, X):\n    \"\"\"\n    Compute the Mahalanobis distances (MD values).\n\n    Parameters\n    ----------\n    X : ndarray of shape (n_samples, n_features)\n        Samples.\n\n    Returns\n    -------\n    MD : ndarray of shape (n_samples, )\n        Mahalanobis distances (MD values).\n    \"\"\"\n    check_is_fitted(self)\n\n    X = self._validate_data(X=X, reset=False)  # type: ignore\n\n    MD = self._mahalanobis(X, self.mean_, self.scale_, self.precision_)\n\n    return MD\n</code></pre>"},{"location":"api/#src.mts.MT.score","title":"<code>score(X, y)</code>","text":"<p>Return the ROCAUC to the given test data and labels.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray of shape (n_samples, n_features)</code> <p>Test samples.</p> required <code>y</code> <code>ndarray of shape (n_samples, )</code> <p>True labels for X. 1 for anomalies/outliers and 0 for inliers.</p> required <p>Returns:</p> Name Type Description <code>score</code> <code>float</code> <p>ROCAUC.</p> Source code in <code>src/mts/_mt.py</code> <pre><code>def score(self, X, y):\n    \"\"\"\n    Return the ROCAUC to the given test data and labels.\n\n    Parameters\n    ----------\n    X : ndarray of shape (n_samples, n_features)\n        Test samples.\n\n    y : ndarray of shape (n_samples, )\n        True labels for X. 1 for anomalies/outliers and 0 for inliers.\n\n    Returns\n    -------\n    score : float\n        ROCAUC.\n    \"\"\"\n    check_is_fitted(self)\n\n    X, y = self._validate_data(X=X, y=y, reset=False)  # type: ignore\n\n    return roc_auc_score(y, self.mahalanobis(X=X))\n</code></pre>"},{"location":"api/#src.mts.MT.score_samples","title":"<code>score_samples(X)</code>","text":"<p>Compute the Mahalanobis distances (MD values).</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray of shape (n_samples, n_features)</code> <p>Samples.</p> required <p>Returns:</p> Name Type Description <code>MD</code> <code>ndarray of shape (n_samples, )</code> <p>MD values.</p> Source code in <code>src/mts/_mt.py</code> <pre><code>def score_samples(self, X):\n    \"\"\"\n    Compute the Mahalanobis distances (MD values).\n\n    Parameters\n    ----------\n    X : ndarray of shape (n_samples, n_features)\n        Samples.\n\n    Returns\n    -------\n    MD : ndarray of shape (n_samples, )\n        MD values.\n    \"\"\"\n    check_is_fitted(self)\n\n    return self.mahalanobis(X=X)\n</code></pre>"},{"location":"api/#src.mts.RT","title":"<code>RT(*, ddof=1, esp=1e-16, threshold=4.0, return_sqrt=False)</code>","text":"<p>               Bases: <code>BaseEstimator</code></p> <p>RT method.</p> <p>The RT method is an unsupervised learning method used for pattern recognition in quality engineering. The method learns the mean of each feature in unit space, the sensitivity and SN ratio of each sample, and the associated covariance matrix of the sensitivity and SN ratio, and computes MD values based on these values.</p> <p>Parameters:</p> Name Type Description Default <code>ddof</code> <code>int</code> <p>It means the delta degrees of freedom. The divisor used in the is <code>N - ddof</code>, where <code>N</code> is the number of samples.</p> <code>1</code> <code>esp</code> <code>float</code> <p>A constant to avoid zero division. It is used in the calculation as <code>1 / (x + esp)</code>.</p> <code>1e-16</code> <code>threshold</code> <code>float</code> <p>Threshold. A multiple of the standard deviation of the MD values in the unit space. If 4, threshold is 4 sigma.</p> <code>4.0</code> <code>return_sqrt</code> <code>bool</code> <p>Return the square root of the MD values or not.</p> <code>False</code> <p>Attributes:</p> Name Type Description <code>mean_X_</code> <code>ndarray of shape (n_features, )</code> <p>Mean values of each feature of the training data.</p> <code>mean_Y_</code> <code>ndarray of shape (2, )</code> <p>Means of sensitivity and error variance reciprocals. Mean_Y_[0]<code>is the sensitivity mean, and Mean_Y_[1]</code> is the error variance reciprocal.</p> <code>covariance_</code> <code>ndarray of shape (2, 2)</code> <p>Variance-covariance matrix of sensitivity and error variance reciprocal.</p> <code>precision_</code> <code>ndarray of shape (2, 2)</code> <p>Adjoint matrix of <code>covariance_</code>.</p> <code>dist_</code> <code>ndarray of shape(n_samples, )</code> <p>Mahalanobis distances of the training set (on which the fit is called) observations.</p> <code>n_features_in_</code> <code>int</code> <p>Number of features seen during fit.</p> <code>feature_names_in_</code> <code>ndarray of shape (n_features_in_, )</code> <p>Names of features seen during the fit. Defined only if X has feature names that are all strings.</p> <p>Methods:</p> Name Description <code>fit</code> <p>Fit the model.</p> <code>predict</code> <p>Predict the labels of X according to the fitted model.</p> <code>fit_predict</code> <p>Perform Fit to X and Return Labels for X.</p> <code>mahalanobis</code> <p>Compute the Mahalanobis distances (MD values).</p> <code>score</code> <p>Return the ROCAUC to the given test data and labels.</p> <code>score_samples</code> <p>Compute the Mahalanobis distances (MD values).</p> Source code in <code>src/mts/_rt.py</code> <pre><code>def __init__(\n    self,\n    *,\n    ddof: int = 1,\n    esp: float = 1e-16,\n    threshold: float = 4.0,\n    return_sqrt: bool = False,\n):\n    \"\"\"\n    Initialize the instance.\n\n    Parameters\n    ----------\n    ddof : int, default=1\n        It means the delta degrees of freedom. The divisor used in the is\n        `N - ddof`, where `N` is the number of samples.\n\n    esp : float, default=1e-16\n        A constant to avoid zero division. It is used in the calculation as\n        `1 / (x + esp)`.\n\n    threshold : float, default=4.0\n        Threshold. A multiple of the standard deviation of the MD values in\n        the unit space. If 4, threshold is 4 sigma.\n\n    return_sqrt : bool, default=False\n        Return the square root of the MD values or not.\n\n    Attributes\n    ----------\n    mean_X_ : ndarray of shape (n_features, )\n        Mean values of each feature of the training data.\n\n    mean_Y_ : ndarray of shape (2, )\n        Means of sensitivity and error variance reciprocals. Mean_Y_[0]` is\n        the sensitivity mean, and Mean_Y_[1]` is the error variance\n        reciprocal.\n\n    covariance_ : ndarray of shape (2, 2)\n        Variance-covariance matrix of sensitivity and error variance\n        reciprocal.\n\n    precision_ : ndarray of shape (2, 2)\n        Adjoint matrix of `covariance_`.\n\n    dist_ : ndarray of shape(n_samples, )\n        Mahalanobis distances of the training set (on which the fit is\n        called) observations.\n\n    n_features_in_ : int\n        Number of features seen during fit.\n\n    feature_names_in_ : ndarray of shape (n_features_in_, )\n        Names of features seen during the fit. Defined only if X has feature\n        names that are all strings.\n    \"\"\"\n    self.ddof = ddof\n    self.esp = esp\n    self.threshold = threshold\n    self.return_sqrt = return_sqrt\n</code></pre>"},{"location":"api/#src.mts.RT.fit","title":"<code>fit(X, y=None)</code>","text":"<p>Fit the model.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray of shape (n_samples, n_features)</code> <p>Training data.</p> required <code>y</code> <code>None</code> <p>Ignored.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>self</code> <code>object</code> <p>Fitted model.</p> Source code in <code>src/mts/_rt.py</code> <pre><code>def fit(self, X, y=None):\n    \"\"\"\n    Fit the model.\n\n    Parameters\n    ----------\n    X : ndarray of shape (n_samples, n_features)\n        Training data.\n\n    y : None\n        Ignored.\n\n    Returns\n    -------\n    self : object\n        Fitted model.\n    \"\"\"\n    self._validate_params()  # type: ignore\n\n    X = self._validate_data(  # type: ignore\n        X=X,\n        reset=True,\n        ensure_min_samples=2,\n        ensure_min_features=2,\n        estimator=self,\n    )\n\n    self.mean_X_ = np.mean(X, axis=0)\n\n    Y = self._compute_Y(X, self.mean_X_)\n\n    self.mean_Y_ = np.mean(Y, axis=0)\n\n    std_Y = Y - self.mean_Y_[None, :]\n\n    self.covariance_ = np.cov(std_Y, rowvar=False, ddof=self.ddof)\n\n    self.precision_ = self._get_precision(self.covariance_)\n\n    self.dist_ = self._mahalanobis(Y, self.mean_Y_, self.precision_)\n\n    self.sigma_ = np.sqrt(np.mean(self.dist_))\n\n    return self\n</code></pre>"},{"location":"api/#src.mts.RT.predict","title":"<code>predict(X, y=None)</code>","text":"<p>Predict the labels of X according to the fitted model.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray of shape (n_samples, n_features)</code> <p>Samples.</p> required <code>y</code> <code>None</code> <p>Ignored.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>labels</code> <code>ndarray of shape (n_samples, )</code> <p>Returns 1 for anomalies/outliers and 0 for inliers.</p> Source code in <code>src/mts/_rt.py</code> <pre><code>def predict(self, X, y=None):\n    \"\"\"\n    Predict the labels of X according to the fitted model.\n\n    Parameters\n    ----------\n    X : ndarray of shape (n_samples, n_features)\n        Samples.\n\n    y : None\n        Ignored.\n\n    Returns\n    -------\n    labels : ndarray of shape (n_samples, )\n        Returns 1 for anomalies/outliers and 0 for inliers.\n    \"\"\"\n    check_is_fitted(self)\n\n    threshold = self.threshold * self.sigma_\n\n    return np.where(self.mahalanobis(X=X) &gt;= threshold, 1, 0)\n</code></pre>"},{"location":"api/#src.mts.RT.fit_predict","title":"<code>fit_predict(X, y=None)</code>","text":"<p>Perform Fit to X and Return Labels for X.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray of shape (n_samples, n_features)</code> <p>Input data.</p> required <code>y</code> <code>None</code> <p>Ignored.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>labels</code> <code>ndarray of shape (n_samples, )</code> <p>Returns 1 for anomalies/outliers and 0 for inliers.</p> Source code in <code>src/mts/_rt.py</code> <pre><code>def fit_predict(self, X, y=None):\n    \"\"\"\n    Perform Fit to X and Return Labels for X.\n\n    Parameters\n    ----------\n    X : ndarray of shape (n_samples, n_features)\n        Input data.\n\n    y : None\n        Ignored.\n\n    Returns\n    -------\n    labels : ndarray of shape (n_samples, )\n        Returns 1 for anomalies/outliers and 0 for inliers.\n    \"\"\"\n    return self.fit(X).predict(X)\n</code></pre>"},{"location":"api/#src.mts.RT.mahalanobis","title":"<code>mahalanobis(X)</code>","text":"<p>Compute the Mahalanobis distances (MD values).</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray of shape (n_samples, n_features)</code> <p>Samples.</p> required <p>Returns:</p> Name Type Description <code>MD</code> <code>ndarray of shape (n_samples, )</code> <p>Mahalanobis distances (MD values).</p> Source code in <code>src/mts/_rt.py</code> <pre><code>def mahalanobis(self, X):\n    \"\"\"\n    Compute the Mahalanobis distances (MD values).\n\n    Parameters\n    ----------\n    X : ndarray of shape (n_samples, n_features)\n        Samples.\n\n    Returns\n    -------\n    MD : ndarray of shape (n_samples, )\n        Mahalanobis distances (MD values).\n    \"\"\"\n    check_is_fitted(self)\n\n    X = self._validate_data(X=X, reset=False)  # type: ignore\n\n    Y = self._compute_Y(X, self.mean_X_)\n\n    MD = self._mahalanobis(Y, self.mean_Y_, self.precision_)\n\n    if self.return_sqrt:\n        MD = np.sqrt(MD)\n\n    return MD\n</code></pre>"},{"location":"api/#src.mts.RT.score","title":"<code>score(X, y)</code>","text":"<p>Return the ROCAUC to the given test data and labels.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray of shape (n_samples, n_features)</code> <p>Test samples.</p> required <code>y</code> <code>ndarray of shape (n_samples, )</code> <p>True labels for X. 1 for anomalies/outliers and 0 for inliers.</p> required <p>Returns:</p> Name Type Description <code>score</code> <code>float</code> <p>ROCAUC.</p> Source code in <code>src/mts/_rt.py</code> <pre><code>def score(self, X, y):\n    \"\"\"\n    Return the ROCAUC to the given test data and labels.\n\n    Parameters\n    ----------\n    X : ndarray of shape (n_samples, n_features)\n        Test samples.\n\n    y : ndarray of shape (n_samples, )\n        True labels for X. 1 for anomalies/outliers and 0 for inliers.\n\n    Returns\n    -------\n    score : float\n        ROCAUC.\n    \"\"\"\n    check_is_fitted(self)\n\n    X, y = self._validate_data(X=X, y=y, reset=False)  # type: ignore\n\n    return roc_auc_score(y, self.mahalanobis(X=X))\n</code></pre>"},{"location":"api/#src.mts.RT.score_samples","title":"<code>score_samples(X)</code>","text":"<p>Compute the Mahalanobis distances (MD values).</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray of shape (n_samples, n_features)</code> <p>Samples.</p> required <p>Returns:</p> Name Type Description <code>MD</code> <code>ndarray of shape (n_samples, )</code> <p>MD values.</p> Source code in <code>src/mts/_rt.py</code> <pre><code>def score_samples(self, X):\n    \"\"\"\n    Compute the Mahalanobis distances (MD values).\n\n    Parameters\n    ----------\n    X : ndarray of shape (n_samples, n_features)\n        Samples.\n\n    Returns\n    -------\n    MD : ndarray of shape (n_samples, )\n        MD values.\n    \"\"\"\n    check_is_fitted(self)\n\n    return self.mahalanobis(X=X)\n</code></pre>"},{"location":"api/#src.mts.T","title":"<code>T(*, tb=False, esp=1e-16, is_simplified=False)</code>","text":"<p>               Bases: <code>RegressorMixin</code>, <code>BaseEstimator</code></p> <p>T(1), T(2), Ta and Tb methods.</p> <p>The T(1), T(2), Ta and Tb methods are supervised learning methods used for regression in quality engineering. The T(1) and T(2) methods divide the training data into unit space and signal data, and learn the mean from the unit space and the sensitivity and SN ratio from the signal data. The Ta method does not divide the training data into unit space and signal data, and learns the mean, sensitivity, and SN ratio from all the training data. The Tb method also learns from all training data, but for each element, the sample with the largest SN ratio is used as the mean.</p> <p>Parameters:</p> Name Type Description Default <code>tb</code> <code>bool</code> <p>Whether to compute as Tb method. If False, compute as T(1), T(2), and Ta methods.</p> <code>False</code> <code>esp</code> <code>float</code> <p>A constant to avoid zero division. It is used in the calculation as <code>1 / (x + esp)</code>.</p> <code>1e-16</code> <code>is_simplified</code> <code>bool</code> <p>Compute the SN ratio using the simplified formula or not. The simplified formula computes with <code>b**2 / ve</code>.</p> <code>False</code> <p>Attributes:</p> Name Type Description <code>mean_X_</code> <code>ndarray of shape (n_features, )</code> <p>Mean values of each feature of the training data.</p> <code>mean_y_</code> <code>float or ndarray of shape (n_features, )</code> <p>Mean value of target values.</p> <code>n_</code> <code>ndarray of shape (n_features, )</code> <p>SN ratio between each feature and the target values.</p> <code>b_</code> <code>ndarray of shape (n_features, )</code> <p>Sensitivity between each feature and target values.</p> <code>n_features_in_</code> <code>int</code> <p>Number of features seen during fit.</p> <code>feature_names_in_</code> <code>ndarray of shape (n_features_in_, )</code> <p>Names of features seen during the fit. Defined only if X has feature names that are all strings.</p> <p>Methods:</p> Name Description <code>fit</code> <p>Fit the model.</p> <code>predict</code> <p>Predict using the fitted model.</p> <code>score</code> <p>Return the SN ratio of the integrated estimate.</p> Source code in <code>src/mts/_t.py</code> <pre><code>def __init__(\n    self, *, tb: bool = False, esp: float = 1e-16, is_simplified: bool = False\n):\n    \"\"\"\n    Initialize the instance.\n\n    Parameters\n    ----------\n    tb : bool, default=False\n        Whether to compute as Tb method. If False, compute as T(1), T(2),\n        and Ta methods.\n\n    esp : float, default=1e-16\n        A constant to avoid zero division. It is used in the calculation as\n        `1 / (x + esp)`.\n\n    is_simplified : bool, default=False\n        Compute the SN ratio using the simplified formula or not. The\n        simplified formula computes with `b**2 / ve`.\n\n    Attributes\n    ----------\n    mean_X_ : ndarray of shape (n_features, )\n        Mean values of each feature of the training data.\n\n    mean_y_ : float or ndarray of shape (n_features, )\n        Mean value of target values.\n\n    n_ : ndarray of shape (n_features, )\n        SN ratio between each feature and the target values.\n\n    b_ : ndarray of shape (n_features, )\n        Sensitivity between each feature and target values.\n\n    n_features_in_ : int\n        Number of features seen during fit.\n\n    feature_names_in_ : ndarray of shape (n_features_in_, )\n        Names of features seen during the fit. Defined only if X has feature\n        names that are all strings.\n    \"\"\"\n    self.tb = tb\n    self.esp = esp\n    self.is_simplified = is_simplified\n</code></pre>"},{"location":"api/#src.mts.T.fit","title":"<code>fit(X, y, *, us_idx=None)</code>","text":"<p>Fit the model.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray of shape (n_samples, n_features)</code> <p>Training data. Includes unit space and signal data.</p> required <code>y</code> <code>ndarray of shape (n_samples, )</code> <p>Target values. Will be cast to X's dtype if necessary.</p> required <code>us_idx</code> <code>array_like of shape (n_samples, ) or None</code> <p>A binary array indicating which sample of the training data is the unit space (0 for the unit space, 1 for the signal data); if None, the training data is not divided into the unit space and the signal data, but is computed as the Ta method. It is ignored when the Tb method is computed.</p> <code>None.</code> <p>Returns:</p> Name Type Description <code>self</code> <code>object</code> <p>Fitted model.</p> Source code in <code>src/mts/_t.py</code> <pre><code>def fit(self, X, y, *, us_idx=None):\n    \"\"\"\n    Fit the model.\n\n    Parameters\n    ----------\n    X : ndarray of shape (n_samples, n_features)\n        Training data. Includes unit space and signal data.\n\n    y : ndarray of shape (n_samples, )\n        Target values. Will be cast to X's dtype if necessary.\n\n    us_idx : array_like of shape (n_samples, ) or None, default=None.\n        A binary array indicating which sample of the training data is the\n        unit space (0 for the unit space, 1 for the signal data); if None,\n        the training data is not divided into the unit space and the signal\n        data, but is computed as the Ta method. It is ignored when the Tb\n        method is computed.\n\n    Returns\n    -------\n    self : object\n        Fitted model.\n    \"\"\"\n    self._validate_params()  # type: ignore\n\n    X, y = self._validate_data(  # type: ignore\n        X=X,\n        y=y,\n        reset=True,\n        y_numeric=True,\n        estimator=self,\n    )\n\n    if self.tb:\n        n = np.empty_like(X)\n        b = np.empty_like(X)\n        for i, (x_i, y_i) in enumerate(zip(X, y)):\n            std_X = X - x_i[None, :]\n            std_y = y - y_i\n\n            n[i], b[i] = self._compute_sn_ratio_and_sensitivity(std_X, std_y)\n\n        idx_row = np.argmax(n, axis=0)\n        idx_col = np.arange(X.shape[1])\n\n        self.mean_X_ = X[idx_row, idx_col]\n        self.mean_y_ = y[idx_row]\n\n        self.b_ = b[idx_row, idx_col]\n        self.n_ = n[idx_row, idx_col]\n    else:\n        if us_idx is None:\n            self.mean_X_ = np.mean(X, axis=0)\n            self.mean_y_ = np.mean(y)\n\n            std_X = X - self.mean_X_[None, :]\n            std_y = y - self.mean_y_\n        else:\n            unit_space_mask = np.where(us_idx == 0, True, False)\n\n            self.mean_X_ = np.mean(X[unit_space_mask], axis=0)\n            self.mean_y_ = np.mean(y[unit_space_mask])\n\n            std_X = X[~unit_space_mask] - self.mean_X_[None, :]\n            std_y = X[~unit_space_mask] - self.mean_y_\n\n        self.n_, self.b_ = self._compute_sn_ratio_and_sensitivity(std_X, std_y)\n\n    return self\n</code></pre>"},{"location":"api/#src.mts.T.predict","title":"<code>predict(X, y=None)</code>","text":"<p>Predict using the fitted model.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray of shape (n_samples, n_features)</code> <p>Samples.</p> required <code>y</code> <code>None</code> <p>Ignored.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>y_pred</code> <code>ndarray of shape (n_samples, )</code> <p>Predict values.</p> Source code in <code>src/mts/_t.py</code> <pre><code>def predict(self, X, y=None):\n    \"\"\"\n    Predict using the fitted model.\n\n    Parameters\n    ----------\n    X : ndarray of shape (n_samples, n_features)\n        Samples.\n\n    y : None\n        Ignored.\n\n    Returns\n    -------\n    y_pred : ndarray of shape (n_samples, )\n        Predict values.\n    \"\"\"\n    check_is_fitted(self)\n\n    X = self._validate_data(X=X, reset=False, estimator=self)  # type: ignore\n\n    std_X = X - self.mean_X_\n\n    M_pred = std_X / (self.b_ + self.esp)[None, :]\n\n    if self.tb:\n        y_pred = M_pred + self.mean_y_[None, :]  # type: ignore\n        y_pred = np.dot(y_pred, self.n_) / (np.sum(self.n_) + self.esp)\n    else:\n        M_pred = np.dot(M_pred, self.n_) / (np.sum(self.n_) + self.esp)\n        y_pred = M_pred + self.mean_y_\n\n    return y_pred\n</code></pre>"},{"location":"api/#src.mts.T.score","title":"<code>score(X, y)</code>","text":"<p>Return the SN ratio of the integrated estimate.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray of shape (n_samples, n_features)</code> <p>Test samples.</p> required <code>y</code> <code>ndarray of shape (n_samples, )</code> <p>True values for X.</p> required <p>Returns:</p> Name Type Description <code>n</code> <code>float</code> <p>SN ratio of the integrated estimate. It is computed from M_True and M_Pred for the T(1), T(2) and Ta methods, and from y_True and y_Pred for the Tb method.</p> Source code in <code>src/mts/_t.py</code> <pre><code>def score(self, X, y):\n    \"\"\"\n    Return the SN ratio of the integrated estimate.\n\n    Parameters\n    ----------\n    X : ndarray of shape (n_samples, n_features)\n        Test samples.\n\n    y : ndarray of shape (n_samples, )\n        True values for X.\n\n    Returns\n    -------\n    n : float\n        SN ratio of the integrated estimate. It is computed from M_True and\n        M_Pred for the T(1), T(2) and Ta methods, and from y_True and y_Pred\n        for the Tb method.\n    \"\"\"\n    check_is_fitted(self)\n\n    X, y = self._validate_data(X=X, y=y, reset=False)  # type: ignore\n\n    if self.tb:\n        M_true = y\n        M_pred = self.predict(X)\n    else:\n        M_true = y - self.mean_y_\n        M_pred = self.predict(X) - self.mean_y_\n\n    n, _ = self._compute_sn_ratio_and_sensitivity(M_pred[:, None], M_true)\n    n = 10 * np.log10(n)\n\n    return n\n</code></pre>"},{"location":"getting-started/","title":"Getting Started","text":""},{"location":"getting-started/#dependencies","title":"Dependencies","text":"<ul> <li>Python (&gt;=3.9)</li> <li>scikit-learn (&gt;=1.4.0)</li> </ul>"},{"location":"getting-started/#installation","title":"Installation","text":"<p>It can be installed as follows using pip:</p> <pre><code>pip install -U mt-system\n</code></pre>"},{"location":"getting-started/#usage","title":"Usage","text":"<p>It learns and predicts like scikit-learn models.</p> <pre><code>from mts import MT\n\nmt = MT(method=\"mt\")\n\nmt.fit(train_X)\n\nlabel = mt.predict(test_X)\n\nmd = mt.mahalanobis(test_X)\n</code></pre> <p>or</p> <pre><code>from mts import MT\n\nmt = MT(method=\"mt\")\n\nlabel = mt.fit(train_X).predict(test_X)\n</code></pre> <p>MT, MTA and SVP methods use the MT model.</p> <pre><code>from mts import MT\n\nmt = MT(method=\"mt\")\n\nmta = MT(method=\"mta\")\n\nsvp = MT(method=\"svp\")\n</code></pre> <p>T(1), T(2), Ta and Tb methods use the T model.</p> <pre><code>from mts import T\n\nt = T(tb=False)  # T(1), T(2), and Ta methods are specified when fitting the model.\ntb = T(tb=True)\n\nt.fit(train_X, us_idx=us_idx)  # T(1) and T(2) methods.\nt.fit(train_X, us_idx=None)  # Ta method.\n</code></pre> <p>RT method use the RT model.</p> <pre><code>from mts import RT\n\nrt = RT()\n</code></pre>"},{"location":"license/","title":"License","text":"<p>BSD-3-Clause License</p> <pre><code>Copyright (c) 2022 Shota Fukuda &lt;st_fukuda@outlook.jp&gt;.\n\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\n1. Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\n2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\n3. Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n</code></pre>"}]}